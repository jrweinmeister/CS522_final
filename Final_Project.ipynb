{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive for access to data."
      ],
      "metadata": {
        "id": "fXN2BgTpOKzB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3teSoXtzvtt",
        "outputId": "166df8cc-d3d9-4364-ac40-7e975d5e44ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "onWDuDrDOUzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sc\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile as wavfile\n",
        "import cv2\n",
        "import librosa\n",
        "\n",
        "# Import sci-kit models\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "dXptQZVP7haW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "VrkDhTp6OfaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = 'gdrive/Shareddrives/COSC 522/Data/'  #change dir to your project folder"
      ],
      "metadata": {
        "id": "ugxJ8jLPz-o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data lists\n",
        "samples = []\n",
        "labels = []\n",
        "classes = os.listdir(root_path)\n",
        "\n",
        "for file in os.listdir(root_path):\n",
        "  print(file)\n",
        "  for filename in os.listdir(root_path+file):\n",
        "    dir_name = root_path+file+\"/\"\n",
        "    print(filename)\n",
        "    \n",
        "    # Define sample rate\n",
        "    fs = 44100\n",
        "\n",
        "    fs_data, y = wavfile.read(os.path.join(dir_name, filename))\n",
        "    if len(y.shape) == 2:\n",
        "        y = y[:,0]\n",
        "    print(fs_data)\n",
        "    print(y[2570])\n",
        "    print(type(y))\n",
        "\n",
        "    if fs_data == fs:\n",
        "        labels.append([file])\n",
        "        samples.append(y)\n",
        "    else:\n",
        "        print('Warning: Data in {} not sampled at 44.1 kHz!'.format(filename))\n",
        "        print(f'Sampled at {fs_data}')\n",
        "        # TODO: Down sample data that is not 44.1 kHz (most seem to be 48.0 kHz)\n",
        "    \n",
        "    print()\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P_apSHQ0Xh4",
        "outputId": "8be727b7-9d26-433c-c28f-3d7b1072a181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dendropsophus bifurcus\n",
            "D-bifurcus-sc10743.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44100\n",
            "-95\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100536.WAV\n",
            "44100\n",
            "15\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100594.WAV\n",
            "44100\n",
            "7713792\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Dbifurcus2.WAV\n",
            "48000\n",
            "100096\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in Dbifurcus2.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "LS100584.WAV\n",
            "44100\n",
            "7324416\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100582.WAV\n",
            "44100\n",
            "12234240\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Drhodopeplusbifurcus2_Daniel1.WAV\n",
            "48000\n",
            "79037440\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in Drhodopeplusbifurcus2_Daniel1.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "LS100303 D. bifurcus sc38590mono.WAV\n",
            "44100\n",
            "498944\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100120.WAV\n",
            "44100\n",
            "-1221888\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "D-bifircus-D-parviceps-LS100120.WAV\n",
            "44100\n",
            "-1221888\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Engystomops petersi\n",
            "E-petersi-km-40-sc10741.WAV\n",
            "44100\n",
            "0\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Epetersi3_Daniel.WAV\n",
            "48000\n",
            "-601856\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in Epetersi3_Daniel.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "Epetersi2_Daniel1.WAV\n",
            "48000\n",
            "171103488\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in Epetersi2_Daniel1.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "E-petersi-sc28417-km22.WAV\n",
            "44100\n",
            "-2309\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "1017-sc28418-E-petersi-km22mono.WAV\n",
            "44100\n",
            "305\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Epetersi_Daniel1.WAV\n",
            "48000\n",
            "667904\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in Epetersi_Daniel1.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "LS100158 E. petersi no capturado_Daniel1.WAV\n",
            "48000\n",
            "154278400\n",
            "<class 'numpy.ndarray'>\n",
            "Warning: Data in LS100158 E. petersi no capturado_Daniel1.WAV not sampled at 44.1 kHz!\n",
            "Sampled at 48000\n",
            "\n",
            "1020-sc-28437-E-petersi-km10MONO_Daniel1.WAV\n",
            "44100\n",
            "46268416\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100150 E. petersi sc28466.WAV\n",
            "44100\n",
            "-55030784\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "1021-sc28494-E-petersi.WAV\n",
            "44100\n",
            "279\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "E-petesi-sc28416-km22.WAV\n",
            "44100\n",
            "8\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "1019-sc28436-E-petersi-km10_Daniel1.WAV\n",
            "44100\n",
            "-339\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Pristimantis conspicillatus\n",
            "LS100308- Pristimantis conspicillatus.WAV\n",
            "44100\n",
            "-14368512\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100313- Pristimantis conspicillatus.WAV\n",
            "44100\n",
            "1090048\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100329sc37220 mn conspicillatus_Daniel2.wav\n",
            "44100\n",
            "-3932160\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100309sc37073.WAV\n",
            "44100\n",
            "-223488\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100319Pconspicillatus.wav\n",
            "44100\n",
            "41472\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100307.WAV\n",
            "44100\n",
            "-19871744\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100456 P. conspicillatus.WAV\n",
            "44100\n",
            "-4\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100326SC37214 mn_Daniel.wav\n",
            "44100\n",
            "-3\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "LS100325sc37213 mn.wav\n",
            "44100\n",
            "-19\n",
            "<class 'numpy.ndarray'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(samples))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1iFq_ETMgBi",
        "outputId": "10f1ddbb-f650-4171-8a3e-0098f651fb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode labels"
      ],
      "metadata": {
        "id": "LpDV974SVO1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape classes list\n",
        "unique_classes = [[c] for c in classes]\n",
        "\n",
        "# Create encoder, fit, and check encoding\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(unique_classes)\n",
        "enc_labels = enc.transform(labels).toarray()\n",
        "print('Encoding is:')\n",
        "print(enc_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFm7OkhQVNeo",
        "outputId": "3d72ce5b-10cc-40fe-968f-927db7e53765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding is:\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in samples:\n",
        "  print(len(sample)/44100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jlQaUMoWNCt",
        "outputId": "8665eaf9-0604-43ab-a6eb-8ee8370a0e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "593.124716553288\n",
            "313.6319954648526\n",
            "317.83473922902493\n",
            "208.70095238095237\n",
            "409.18204081632655\n",
            "240.3265306122449\n",
            "105.79011337868481\n",
            "105.79011337868481\n",
            "641.0274829931973\n",
            "1018.5607256235828\n",
            "512.5514739229025\n",
            "368.0304761904762\n",
            "356.8213378684807\n",
            "319.9651700680272\n",
            "504.0065306122449\n",
            "419.48589569161\n",
            "227.33519274376417\n",
            "307.52507936507936\n",
            "257.4871428571429\n",
            "203.3603628117914\n",
            "119.8402947845805\n",
            "264.05732426303854\n",
            "80.80410430839002\n",
            "200.45142857142858\n",
            "235.82185941043085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Spectrograms"
      ],
      "metadata": {
        "id": "szbETrq7cvJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spectrograms(time_data, FFT_SIZE=1024, fs=44100):\n",
        "    ## Compute Fast Fourier Transform of data\n",
        "    # Create FFT lists\n",
        "    pxx = []\n",
        "    \n",
        "    print(\"Calculating FFTs for data ...\")\n",
        "    for sample in time_data:\n",
        "        # flatten() is used because some of the data is stereo rather than mono. This results in having\n",
        "        # two data points for each data point rather than 1, and something like (# data points, 2) vs. (# data points, ).\n",
        "        # flatten(), flattens out the second dimension, resulting in (2x # data points, )\n",
        "#             if windows is True:\n",
        "        _, _, pxx_idx = signal.spectrogram(sample, nperseg=FFT_SIZE, fs=fs, noverlap=FFT_SIZE/2)\n",
        "        \n",
        "        pxx.append(pxx_idx)\n",
        "                            \n",
        "    print('Calculated all FFTs')\n",
        "\n",
        "    return pxx.copy()"
      ],
      "metadata": {
        "id": "fziIJu_wXRpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specs = get_spectrograms(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbNO827WXgUW",
        "outputId": "c533375c-8f94-4fb4-dccb-29e1af82273a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating FFTs for data ...\n",
            "Calculated all FFTs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(specs))\n",
        "print(len(specs[0]))\n",
        "print(len(specs[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RjKH8pDZAMa",
        "outputId": "13421492-4dd1-4571-9443-3320ddde687e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "513\n",
            "51086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binning Data"
      ],
      "metadata": {
        "id": "R6ddv2pYctF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bins(spec_data, num_freq_bins=5, num_time_bins=5):\n",
        "    binned_data = []\n",
        "        \n",
        "    # Get individual samples\n",
        "    for s in spec_data:\n",
        "        #Open CV's resize takes (columns,rows) as the input for desired size\n",
        "        resized_pxx=cv2.resize(s[:,:],(num_time_bins,num_freq_bins))\n",
        "        binned_data.append(resized_pxx.flatten())\n",
        "            \n",
        "    return binned_data"
      ],
      "metadata": {
        "id": "CXo9zG8xcsnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binned_data = get_bins(specs)"
      ],
      "metadata": {
        "id": "gpqMD2dFc2p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.array(binned_data)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCZyliySdqWt",
        "outputId": "2a19de86-b5c4-4e6d-8f7b-11b61c7b9f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Freq-Windows"
      ],
      "metadata": {
        "id": "TqEn4D-acb_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_freq_windows(time_data, len_window=1, overlap=0, sample_rate=10):\n",
        "    len_data = time_data.shape[1]\n",
        "#     print(len_data)\n",
        "    \n",
        "    windows = []\n",
        "    \n",
        "    # How far the window should shift\n",
        "    if overlap == 0:\n",
        "        step = len_window\n",
        "        \n",
        "        start = 0\n",
        "        stop = step\n",
        "#         print(len_window)\n",
        "        for n in range(int(len_data/len_window)):\n",
        "            windows.append(time_data[:, start:stop])\n",
        "            \n",
        "#             print(start)\n",
        "#             print(stop)\n",
        "#             print()\n",
        "            start = start + step\n",
        "            stop = stop + step\n",
        "            \n",
        "            if start > len_data or stop > len_data:\n",
        "                break\n",
        "    else:\n",
        "        step = int(len_window*overlap)\n",
        "        \n",
        "        start = 0\n",
        "        stop = len_window\n",
        "        \n",
        "#         print(len_window)\n",
        "        for n in range(int(len_data/step)):\n",
        "            windows.append(time_data[:, start:stop])\n",
        "            \n",
        "#             print(start)\n",
        "#             print(stop)\n",
        "#             print()\n",
        "            start = start + step\n",
        "            stop = stop + step\n",
        "            \n",
        "            if start > len_data or stop > len_data:\n",
        "                break\n",
        "        \n",
        "    return windows"
      ],
      "metadata": {
        "id": "KGspW27Rce5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_freq = []\n",
        "for fft in specs:\n",
        "    window_freq_data = get_windows(fft, len_window=2, overlap=.5)\n",
        "    #shape = np.array(window_data).shape\n",
        "    #window_data = np.array(window_data).reshape(shape[0], shape[1]*shape[2]) \n",
        "    print(np.array(window_data).shape)\n",
        "    windowed_freq.append(window_data)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3lhNbcqc2Wd",
        "outputId": "6de6468b-c168-47be-a459-f53a30457b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51085, 513, 2)\n",
            "(27012, 513, 2)\n",
            "(27374, 513, 2)\n",
            "(17974, 513, 2)\n",
            "(35242, 513, 2)\n",
            "(20698, 513, 2)\n",
            "(9110, 513, 2)\n",
            "(9110, 513, 2)\n",
            "(55211, 513, 2)\n",
            "(87729, 513, 2)\n",
            "(44145, 513, 2)\n",
            "(31697, 513, 2)\n",
            "(30732, 513, 2)\n",
            "(27557, 513, 2)\n",
            "(43409, 513, 2)\n",
            "(36129, 513, 2)\n",
            "(19579, 513, 2)\n",
            "(26486, 513, 2)\n",
            "(22176, 513, 2)\n",
            "(17514, 513, 2)\n",
            "(10320, 513, 2)\n",
            "(22742, 513, 2)\n",
            "(6957, 513, 2)\n",
            "(17263, 513, 2)\n",
            "(20310, 513, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Time-Windows"
      ],
      "metadata": {
        "id": "_4ryaczTeG8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_windows(time_data, len_window_sec=1, overlap=0):\n",
        "  len_data = time_data.shape[0]\n",
        "  # print(len_data)\n",
        "\n",
        "  len_window = len_window_sec*44100\n",
        "    \n",
        "  windows = []\n",
        "  # How far the window should shift\n",
        "  if overlap == 0:\n",
        "      step = len_window\n",
        "      \n",
        "      start = 0\n",
        "      stop = step\n",
        "      # print(len_window)\n",
        "\n",
        "      for n in range(int(len_data/len_window)):\n",
        "          windows.append(time_data[start:stop])\n",
        "          \n",
        "          # print(start)\n",
        "          # print(stop)\n",
        "          # print()\n",
        "          start = start + step\n",
        "          stop = stop + step\n",
        "          \n",
        "          if start > len_data or stop > len_data:\n",
        "              break\n",
        "  else:\n",
        "      step = int(len_window*overlap)\n",
        "      \n",
        "      start = 0\n",
        "      stop = len_window\n",
        "      \n",
        "  #         print(len_window)\n",
        "      for n in range(int(len_data/step)):\n",
        "          windows.append(time_data[start:stop])\n",
        "          \n",
        "  #             print(start)\n",
        "  #             print(stop)\n",
        "  #             print()\n",
        "          start = start + step\n",
        "          stop = stop + step\n",
        "          \n",
        "          if start > len_data or stop > len_data:\n",
        "              break\n",
        "        \n",
        "  return windows\n",
        "\n",
        "time_windows = []\n",
        "num_labels = []\n",
        "for sample in samples:\n",
        "  new_windows = get_time_windows(samples[0], len_window_sec=5)\n",
        "  num_labels.append(len(new_windows))\n",
        "  print(np.array(new_windows).shape)\n",
        "  time_windows = time_windows + new_windows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvtM9gi8exex",
        "outputId": "3fbc63e4-a1a3-4221-e939-dc66d78ed446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n",
            "(118, 220500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_labels = []\n",
        "for label in labels:\n",
        "  new_labels = new_labels + [label for num in num_labels]\n",
        "\n",
        "enc_labels = enc.transform(new_labels).toarray()\n",
        "print('Encoding is:')\n",
        "print(enc_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wfBEePwibjN",
        "outputId": "8ee991e1-d1e2-4f3d-ec2b-69eb7c716552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding is:\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = cv.split(np.array(X), np.array(y.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Hp3oBzbmgtly",
        "outputId": "a5efa75a-4e4a-4cce-b676-724476da82a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-3fcb7c9057dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \"\"\"\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2950, 625]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "bpBXaHp0pf9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specs_reshape = []\n",
        "for i in range(len(specs)):\n",
        "  shape = np.array(specs[i]).shape\n",
        "  X = np.array(specs[i]).reshape(shape[0]*shape[1])\n",
        "  specs_reshape.append(X)\n",
        "  "
      ],
      "metadata": {
        "id": "msEbVr5CpkxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_numbers = 20 ## need to be determined\n",
        "domain_fv = []\n",
        "\n",
        "for i in range(len(specs_reshape)):\n",
        "  \n",
        "    # MFCC\n",
        "    mfccs = librosa.feature.mfcc(y=specs_reshape[i], sr=44100, n_mfcc=20, win_length = int(np.ceil(1024/window_numbers)), hop_length = int(np.ceil(1024/(2*window_numbers))))\n",
        "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "    #mfccs_mean=mfccs_mean.reshape(513,20)\n",
        "\n",
        "    # Spectral Centroid\n",
        "#     sc = librosa.feature.spectral_centroid(y=spectrograms[i], sr=44100, win_length = int(np.ceil(1024/5)), hop_length = int(np.ceil(1024/10)))\n",
        "#     reshape_sc=[]\n",
        "#     for x in sc:\n",
        "#         for j in x:\n",
        "#             reshape_sc.append(j)\n",
        "\n",
        "    #all_features=list(zip(mfccs_mean,reshape_sc))\n",
        "    domain_fv.append(mfccs_mean)\n",
        "    "
      ],
      "metadata": {
        "id": "AQxksTrXpnGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flMbJaetqcdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "EReY11hZdz2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify which data to use, these are the only parameters that should change, the rest should remain the same.\n",
        "X = time_windows\n",
        "y = enc_labels\n",
        "depth = 5\n",
        "\n",
        "\n",
        "# # Create our imputer to replace missing values with the mean \n",
        "# imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# imp = imp.fit(X)\n",
        "    \n",
        "# # Impute our data\n",
        "# X_imp = imp.transform(X)\n",
        "\n",
        "# Define model\n",
        "clf = RandomForestClassifier(max_depth=depth, random_state=0)\n",
        "\n",
        "# Define number of folds\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=False)\n",
        "\n",
        "# Split data, train and test model on 10 folds\n",
        "split = 1\n",
        "scores = []\n",
        "confuse_mat = []\n",
        "for train_index, test_index in cv.split(np.array(X), np.array(y.argmax(axis=1))):\n",
        "    print(f\"Split {split}/10...\")\n",
        "    x_train, y_train = X[train_index], enc_labels[train_index]\n",
        "    x_test, y_test = X[test_index], enc_labels[test_index]\n",
        "    \n",
        "    \n",
        "    # Fit model and evaluate it\n",
        "    clf.fit(x_train, y_train)\n",
        "    scores.append(clf.score(x_test, y_test))\n",
        "    \n",
        "    # Construct confusion matrix\n",
        "    y_predict = clf.predict(x_test)\n",
        "    confuse_mat.append(confusion_matrix(y_test.argmax(axis=1), y_predict.argmax(axis=1)))\n",
        "    \n",
        "    # Iterate\n",
        "    split = split + 1\n",
        "    \n",
        "print(\"Mean accuracy:\" + str(np.mean(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "8r2UmYQmeGb4",
        "outputId": "93836824-bceb-4e1f-8d59-57cfce996d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f0ddeb367ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mconfuse_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Split {split}/10...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \"\"\"\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2950, 625]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: should probably do kfold but doing this just for testing purposes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(binned_data, enc_labels, test_size=.3, stratify=enc_labels)"
      ],
      "metadata": {
        "id": "LAMP1ouNdzQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(clf.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOmvyKZAfBv_",
        "outputId": "bcd5c00b-48c7-4324-bc7a-a581a595e6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "ZG2uK2hZvEh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pkl_filename = \"pickle_model.pkl\"\n",
        "\n",
        "# Note, for now this will only store the file in volitle memory in the notebook\n",
        "# To save permanently, most add file path to drive\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "  pickle.dump(clf, file)"
      ],
      "metadata": {
        "id": "E4cyLfFqgIY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "Cuqmt22ZvGh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pkl_filename, 'rb') as file:\n",
        "  pickle_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "bdAfRQ1svJ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test saved model\n",
        "print(pickle_model.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCb5zXxpvnWi",
        "outputId": "e2fbea4d-480c-4344-a13d-49a15feb0741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    }
  ]
}